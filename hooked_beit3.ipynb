{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/William-Chittavong/torchscale.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT OFF: hook has wrong path for imports. change them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchscale 0.2.0\n",
      "Uninstalling torchscale-0.2.0:\n",
      "  Successfully uninstalled torchscale-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torchscale -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/William-Chittavong/torchscale.git\n",
      "  Cloning https://github.com/William-Chittavong/torchscale.git to /tmp/pip-req-build-hwpp4owu\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/William-Chittavong/torchscale.git /tmp/pip-req-build-hwpp4owu\n",
      "  Resolved https://github.com/William-Chittavong/torchscale.git to commit c199aff41ceaba9a8fb649fabc9f58150ba3a977\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops in /home/william/envs/beit3/lib/python3.10/site-packages (from torchscale==0.2.0) (0.8.0)\n",
      "Requirement already satisfied: fairscale==0.4.0 in /home/william/envs/beit3/lib/python3.10/site-packages (from torchscale==0.2.0) (0.4.0)\n",
      "Requirement already satisfied: timm==0.6.13 in /home/william/envs/beit3/lib/python3.10/site-packages (from torchscale==0.2.0) (0.6.13)\n",
      "Requirement already satisfied: torch>=1.8 in /home/william/envs/beit3/lib/python3.10/site-packages (from torchscale==0.2.0) (2.3.1+cu118)\n",
      "Requirement already satisfied: huggingface-hub in /home/william/envs/beit3/lib/python3.10/site-packages (from timm==0.6.13->torchscale==0.2.0) (0.23.4)\n",
      "Requirement already satisfied: torchvision in /home/william/envs/beit3/lib/python3.10/site-packages (from timm==0.6.13->torchscale==0.2.0) (0.18.1+cu118)\n",
      "Requirement already satisfied: pyyaml in /home/william/envs/beit3/lib/python3.10/site-packages (from timm==0.6.13->torchscale==0.2.0) (6.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (11.8.89)\n",
      "Requirement already satisfied: triton==2.3.1 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (2.3.1)\n",
      "Requirement already satisfied: fsspec in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (10.3.0.86)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (4.9.0)\n",
      "Requirement already satisfied: filelock in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (11.8.89)\n",
      "Requirement already satisfied: networkx in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (3.2.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (11.8.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.7.0.84 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (8.7.0.84)\n",
      "Requirement already satisfied: jinja2 in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (3.1.3)\n",
      "Requirement already satisfied: sympy in /home/william/envs/beit3/lib/python3.10/site-packages (from torch>=1.8->torchscale==0.2.0) (1.12)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/william/envs/beit3/lib/python3.10/site-packages (from huggingface-hub->timm==0.6.13->torchscale==0.2.0) (4.66.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/william/envs/beit3/lib/python3.10/site-packages (from huggingface-hub->timm==0.6.13->torchscale==0.2.0) (24.1)\n",
      "Requirement already satisfied: requests in /home/william/envs/beit3/lib/python3.10/site-packages (from huggingface-hub->timm==0.6.13->torchscale==0.2.0) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/william/envs/beit3/lib/python3.10/site-packages (from jinja2->torch>=1.8->torchscale==0.2.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/william/envs/beit3/lib/python3.10/site-packages (from sympy->torch>=1.8->torchscale==0.2.0) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/william/envs/beit3/lib/python3.10/site-packages (from torchvision->timm==0.6.13->torchscale==0.2.0) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/william/envs/beit3/lib/python3.10/site-packages (from torchvision->timm==0.6.13->torchscale==0.2.0) (10.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/william/envs/beit3/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.6.13->torchscale==0.2.0) (2024.6.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/william/envs/beit3/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.6.13->torchscale==0.2.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/william/envs/beit3/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.6.13->torchscale==0.2.0) (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/william/envs/beit3/lib/python3.10/site-packages (from requests->huggingface-hub->timm==0.6.13->torchscale==0.2.0) (3.3.2)\n",
      "Using legacy 'setup.py install' for torchscale, since package 'wheel' is not installed.\n",
      "Installing collected packages: torchscale\n",
      "  Running setup.py install for torchscale ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed torchscale-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/William-Chittavong/torchscale.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchscale.model.BEiT3 import create_beit3_retrieval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchscale.component.hook import HookManager\n",
    "hook = HookManager()\n",
    "model_size = \"base\"\n",
    "img_size = 224\n",
    "\n",
    "retrieve_model = create_beit3_retrieval_model(model_size='base',hook_manager= hook, img_size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ckpt from https://github.com/addf400/files/releases/download/beit3/beit3_base_itc_patch16_224.pth\n",
      "Load state_dict by model_key = model\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "from torchscale.component.beit3_utils import load_model_and_may_interpolate\n",
    "\n",
    "\n",
    "from transformers import XLMRobertaTokenizer\n",
    "from PIL import Image\n",
    "\n",
    "tokenizer = XLMRobertaTokenizer(\"/home/william/Documents/GitHub/torchscale/beit3.spm\")\n",
    "\n",
    "image_path = \"/home/william/project/images/catdog.png\"\n",
    "image = Image.open(image_path)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to the size expected by the model\n",
    "    transforms.ToTensor(),          # Convert to tensor\n",
    "])\n",
    "\n",
    "img_tensor = transform(image).unsqueeze(0).requires_grad_(True)\n",
    "img_tensor = img_tensor.to(device)\n",
    "\n",
    "checkpoint_path = \"https://github.com/addf400/files/releases/download/beit3/beit3_base_patch16_224.pth\"\n",
    "\n",
    "image_text_contrastive_checkpoint = \"https://github.com/addf400/files/releases/download/beit3/beit3_base_itc_patch16_224.pth\"\n",
    "\n",
    "\n",
    "# Load the checkpoint into vqa_fixed\n",
    "#load_model_and_may_interpolate(checkpoint_path, vqa_model, model_key='model', model_prefix='')\n",
    "\n",
    "load_model_and_may_interpolate(image_text_contrastive_checkpoint, retrieve_model, model_key='model', model_prefix='')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchscale.component.prs_hook import hook_prs_logger\n",
    "retrieve_model.to(device)\n",
    "retrieve_model.eval()\n",
    "\n",
    "encoder_embed_dim = 768\n",
    "prs = hook_prs_logger(retrieve_model,encoder_embed_dim  ,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BEiT3ForRetrieval(\n",
       "  (beit3): BEiT3(\n",
       "    (text_embed): TextEmbedding(64010, 768)\n",
       "    (vision_embed): VisionEmbedding(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "      (embed_positions): MutliwayEmbedding(\n",
       "        (A): PositionalEmbedding(199, 768)\n",
       "        (B): PositionalEmbedding(1024, 768)\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x EncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (k_proj): MultiwayNetwork(\n",
       "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (v_proj): MultiwayNetwork(\n",
       "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (q_proj): MultiwayNetwork(\n",
       "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (out_proj): MultiwayNetwork(\n",
       "              (A): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (B): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (inner_attn_ln): MultiwayNetwork(\n",
       "              (A): LayerNorm()\n",
       "              (B): LayerNorm()\n",
       "            )\n",
       "            (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (self_attn_layer_norm): MultiwayNetwork(\n",
       "            (A): LayerNorm()\n",
       "            (B): LayerNorm()\n",
       "          )\n",
       "          (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "          (ffn): MultiwayNetwork(\n",
       "            (A): FeedForwardNetwork(\n",
       "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (ffn_layernorm): LayerNorm()\n",
       "            )\n",
       "            (B): FeedForwardNetwork(\n",
       "              (activation_dropout_module): Dropout(p=0.0, inplace=False)\n",
       "              (dropout_module): Dropout(p=0.0, inplace=False)\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (ffn_layernorm): LayerNorm()\n",
       "            )\n",
       "          )\n",
       "          (final_layer_norm): MultiwayNetwork(\n",
       "            (A): LayerNorm()\n",
       "            (B): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): MultiwayNetwork(\n",
       "        (A): LayerNorm()\n",
       "        (B): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (language_head): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (vision_head): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (criterion): ClipLoss()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      2\u001b[0m     rep \u001b[38;5;241m=\u001b[39m retrieve_model(image\u001b[38;5;241m=\u001b[39mimg_tensor,only_infer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m     attentions,mlps \u001b[38;5;241m=\u001b[39m \u001b[43mprs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/beit3/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/beit3/lib/python3.10/site-packages/torchscale/component/prs_hook.py:104\u001b[0m, in \u001b[0;36mPRSLogger.finalize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinalize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    103\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"We calculate the post-ln scaling, project it and normalize by the last norm.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattentions \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    106\u001b[0m     )  \u001b[38;5;66;03m# [b, l, n, h, d]\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlps, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# [b, l + 1, d]\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     projected_attentions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_normalize_attentions()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    rep = retrieve_model(image=img_tensor,only_infer = True)\n",
    "    attentions,mlps = prs.finalize()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "beit3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
